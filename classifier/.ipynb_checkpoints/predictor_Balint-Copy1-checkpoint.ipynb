{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/deeplearn/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiying in: /mnt/TissueCyte80TB/181024_Gerald_HET/het-Mosaic/Ch2_Stitched_Sections/counts_v5_Balint/LGd-sh_multi_v5_count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 565/3440 [00:57<04:51,  9.86it/s]"
     ]
    }
   ],
   "source": [
    "#============================================================================================\n",
    "# Cell Counting Predictor - Parallel version\n",
    "# Author: Gerald M\n",
    "#\n",
    "# This script uses a convolution neural network classifier, trained on manually identified\n",
    "# cells, to confirm whether a potential cell/neuron is correctly identified.\n",
    "#\n",
    "# This version uses a parallel thread.\n",
    "#\n",
    "# Installation:\n",
    "# 1) Navigate to the folder containing cc_predictor_par.py\n",
    "#\n",
    "# Instructions:\n",
    "# 1) Fill in the user defined parameters from line 94\n",
    "# 2) Run the script in a Python IDE\n",
    "#============================================================================================\n",
    "\n",
    "from __future__ import division\n",
    "import os, sys, warnings, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from xml.dom import minidom\n",
    "from multiprocessing import Pool, cpu_count, Array, Manager\n",
    "from contextlib import closing\n",
    "from functools import partial\n",
    "import tqdm\n",
    "import csv\n",
    "from natsort import natsorted\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import glob\n",
    "\n",
    "#=============================================================================================\n",
    "# Define function for predictions\n",
    "#=============================================================================================\n",
    "\n",
    "# Appends cell coordinates to manager list - manager allows access from a thread\n",
    "def append_cell(coord):\n",
    "    cell_markers.append(coord)\n",
    "\n",
    "# Appends no-cell coordinates to manager list - manager allows access from a thread\n",
    "def append_nocell(coord):\n",
    "    nocell_markers.append(coord)\n",
    "\n",
    "# Function to predict/classify object as cell or no-cell\n",
    "def cellpredict(cell, model_weights_path, model_json_path, marker, image_path, filename, cell_markers, nocell_markers):\n",
    "    # Import modules - required for each independant thread\n",
    "    import keras\n",
    "    from keras.preprocessing import image\n",
    "    from keras.models import load_model, model_from_json\n",
    "\n",
    "    # Warning supression and allowing large images to be laoded\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "    warnings.simplefilter('ignore', Image.DecompressionBombWarning)\n",
    "    Image.MAX_IMAGE_PIXELS = 1000000000\n",
    "\n",
    "    # Load the classifier model\n",
    "    json_file = open(model_json_path, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.load_weights(model_weights_path)\n",
    "\n",
    "    # Load each image then crop for the cell\n",
    "    # img = Image.open(os.path.join(image_path, filename[marker[cell, 2]])).crop((marker[cell, 1]-40, marker[cell, 0]-40, marker[cell, 1]+40, marker[cell, 0]+40))\n",
    "    img = Image.open(os.path.join(image_path, filename[marker[cell, 2]-1])).crop((marker[cell, 0]-40, marker[cell, 1]-40, marker[cell, 0]+40, marker[cell, 1]+40))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "\n",
    "    # Predict 0 or 1\n",
    "    prediction = model.predict(np.asarray(img))\n",
    "\n",
    "    if prediction[0][0] == 1: # Cell\n",
    "        cell_value = 1\n",
    "        append_cell(marker[cell,:])\n",
    "        #image.array_to_img(cell_crop[0,:,:,:]).save('/Users/gm515/Desktop/cell_par/'+str(cell)+'.tif')\n",
    "    else: # No cell\n",
    "        cell_value = 0\n",
    "        append_nocell(marker[cell,:])\n",
    "        #image.array_to_img(cell_crop[0,:,:,:]).save('/Users/gm515/Desktop/nocell_par/'+str(cell)+'.tif')\n",
    "\n",
    "    result[cell] = cell_value\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Main function\n",
    "if __name__ == '__main__':\n",
    "    #=============================================================================================\n",
    "    # User definied parameters\n",
    "    #=============================================================================================\n",
    "\n",
    "    # CNN model paths\n",
    "    model_weights_path = 'models/2019_01_29/cc_model_2019_01_29.h5'\n",
    "    model_json_path = 'models/2019_01_29/cc_model_2019_01_29.json'\n",
    "\n",
    "    # Directory path to the files containing the cell coordinates\n",
    "    count_path = '/mnt/TissueCyte80TB/181024_Gerald_HET/het-Mosaic/Ch2_Stitched_Sections/counts_v5_Balint'\n",
    "\n",
    "    # Directory path to the TIFF files containing the cells\n",
    "    image_path = '/mnt/TissueCyte80TB/181024_Gerald_HET/het-Mosaic/Ch2_Stitched_Sections'\n",
    "\n",
    "    #=============================================================================================\n",
    "    # Loop through the coordinate files and predict cells\n",
    "    #=============================================================================================\n",
    "\n",
    "    # Get list of files containing the coordinates in x, y, z\n",
    "    #image_path = raw_input('Counting file path (drag-and-drop): ').strip('\\'').rstrip()\n",
    "    filename = natsorted([file for file in os.listdir(image_path) if file.endswith('.tif')])\n",
    "\n",
    "    if os.path.isdir(count_path):\n",
    "        all_marker_path = glob.glob(count_path+'/*.csv')\n",
    "    else:\n",
    "        all_marker_path = count_path\n",
    "\n",
    "    # Create empty pands dataframe to store data\n",
    "    df = pd.DataFrame(columns = ['ROI', 'Original', 'True', 'False'])\n",
    "\n",
    "    for marker_path in all_marker_path:\n",
    "\n",
    "        marker_filename, marker_file_extension = os.path.splitext(marker_path)\n",
    "\n",
    "        if marker_file_extension == '.xml':\n",
    "            xml_doc = minidom.parse(marker_path)\n",
    "\n",
    "            marker_x = xml_doc.getElementsByTagName('MarkerX')\n",
    "            marker_y = xml_doc.getElementsByTagName('MarkerY')\n",
    "            marker_z = xml_doc.getElementsByTagName('MarkerZ')\n",
    "\n",
    "            marker = np.empty((0,3), int)\n",
    "\n",
    "            for elem in range (0, marker_x.length):\n",
    "                marker = np.vstack((marker, [int(marker_x[elem].firstChild.data), int(marker_y[elem].firstChild.data), int(marker_z[elem].firstChild.data)]))\n",
    "        if marker_file_extension == '.csv':\n",
    "            marker = np.genfromtxt(marker_path, delimiter=',', dtype=np.float).astype(int)\n",
    "\n",
    "        #=============================================================================================\n",
    "        # Load images and correct cell count by predicting\n",
    "        #=============================================================================================\n",
    "\n",
    "        manager = Manager()\n",
    "        result = Array('i', marker.shape[0])\n",
    "        cell_markers = manager.list()\n",
    "        nocell_markers = manager.list()\n",
    "\n",
    "        cell_index = range(marker.shape[0])\n",
    "\n",
    "        print 'Classifiying in: '+marker_filename\n",
    "\n",
    "        tstart = time.time()\n",
    "        pool = Pool(cpu_count())\n",
    "        res = list(tqdm.tqdm(pool.imap(partial(cellpredict, model_weights_path=model_weights_path, model_json_path=model_json_path, marker=marker, image_path=image_path, filename=filename, cell_markers=cell_markers, nocell_markers=nocell_markers), cell_index), total=marker.shape[0]))\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        # Append to Pandas dataframe\n",
    "        df = df.append({'ROI':marker_filename.split('/')[-1][:-9], 'Original': result[:].count(1)+result[:].count(0), 'True': result[:].count(1), 'False': result[:].count(0)}, ignore_index=True)\n",
    "\n",
    "        # Write dataframe to csv\n",
    "        df.to_csv('/home/ml3816/ml3816/cell_counting/cell_counting/classifier/counts_cc_corrected.csv', index=False)\n",
    "\n",
    "print df\n",
    "print '{0:.0f}:{1:.0f} (MM:SS)'.format(*divmod(time.time()-tstart,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
