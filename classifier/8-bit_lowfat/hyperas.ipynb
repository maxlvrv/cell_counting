{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/deeplearn/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! Files detected in test data directory!\n",
      "Moving files back to training data directory...\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import skimage as ski\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "#=============================================================================================\n",
    "# Precheck on directory structure\n",
    "#=============================================================================================\n",
    "\n",
    "if os.listdir('test_data/cell/'):\n",
    "    print('Warning! Files detected in test data directory!')\n",
    "    print('Moving files back to training data directory...')\n",
    "\n",
    "    for f in os.listdir('test_data/cell/'):\n",
    "        shutil.move('test_data/cell/'+f,'training_data/cell/'+f)\n",
    "\n",
    "    for f in os.listdir('test_data/nocell/'):\n",
    "        shutil.move('test_data/nocell/'+f,'training_data/nocell/'+f)\n",
    "        \n",
    "    print('Done!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cell_data = os.listdir('training_data/cell/')\n",
    "nocell_data = os.listdir('training_data/nocell/')\n",
    "\n",
    "validation_cell_data = random.sample(cell_data, int(0.3*len(cell_data)))\n",
    "validation_nocell_data = random.sample(nocell_data, int(0.3*len(nocell_data)))\n",
    "\n",
    "for f in validation_cell_data:\n",
    "    shutil.move('training_data/cell/'+f,'test_data/cell/'+f)\n",
    "\n",
    "for f in validation_nocell_data:\n",
    "    shutil.move('training_data/nocell/'+f,'test_data/nocell/'+f)\n",
    "\n",
    "print('Done!\\n')\n",
    "    \n",
    "# celllist = []\n",
    "# for names in cell_data:\n",
    "#     if names.endswith(\".tif\"):\n",
    "#         celllist.append(names)\n",
    "# print celllist\n",
    "# print cell_data\n",
    "\n",
    "# nocelllist = []\n",
    "# for names in nocell_data:\n",
    "#     if names.endswith(\".tif\"):\n",
    "#         nocelllist.append(names)\n",
    "# print nocelllist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import random\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import shutil\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import skimage as ski\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.image as mpimg\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense': hp.choice('Dense', [256, 512, 1024]),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'Dropout_2': hp.choice('Dropout_2', ['three', 'four']),\n",
      "        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: \"\"\"\n",
      "   3: Data providing function:\n",
      "   4: \n",
      "   5: This function is separated from create_model() so that hyperopt\n",
      "   6: won't reload data for each evaluation run.\n",
      "   7: \"\"\"  \n",
      "   8: cell_data = os.listdir('training_data/cell/')\n",
      "   9: nocell_data = os.listdir('training_data/nocell/')\n",
      "  10: \n",
      "  11: # Training data\n",
      "  12: path = 'training_data/cell/'\n",
      "  13: x_train = []\n",
      "  14: y_train = []\n",
      "  15: for f in cell_data:\n",
      "  16:     im = mpimg.imread(str(path)+f)\n",
      "  17:     x_train.append(im)\n",
      "  18:     y_train.append(1)\n",
      "  19: path = 'training_data/nocell/'\n",
      "  20: for f in nocell_data:\n",
      "  21:     im = mpimg.imread(str(path)+f)\n",
      "  22:     x_train.append(im)\n",
      "  23:     y_train.append(0)\n",
      "  24: \n",
      "  25: cell_test_data = os.listdir('test_data/cell/')\n",
      "  26: nocell_test_data = os.listdir('test_data/nocell/')\n",
      "  27: \n",
      "  28: # Validation data\n",
      "  29: path = 'test_data/cell/'\n",
      "  30: x_test = []\n",
      "  31: y_test = []\n",
      "  32: for f in cell_test_data:\n",
      "  33:     im = mpimg.imread(str(path)+f)\n",
      "  34:     x_test.append(im)\n",
      "  35:     y_test.append(1)\n",
      "  36: path = 'test_data/nocell/'\n",
      "  37: for f in nocell_test_data:\n",
      "  38:     im = mpimg.imread(str(path)+f)\n",
      "  39:     x_test.append(im)\n",
      "  40:     y_test.append(0)\n",
      "  41:     \n",
      "  42: \n",
      "  43: x_train = np.asarray(x_train, dtype=np.float32)\n",
      "  44: y_train = np.asarray(y_train, dtype=np.float32)\n",
      "  45: x_test = np.asarray(x_test, dtype=np.float32)\n",
      "  46: y_test = np.asarray(y_test, dtype=np.float32)\n",
      "  47: \n",
      "  48: x_train = x_train.reshape(x_train.shape[0], 80, 80, 1)\n",
      "  49: x_test = x_test.reshape(x_test.shape[0], 80, 80, 1)\n",
      "  50: x_train = x_train.astype('float32')\n",
      "  51: x_test = x_test.astype('float32')\n",
      "  52: x_train /= 255\n",
      "  53: x_test /= 255\n",
      "  54: nb_classes = 2\n",
      "  55: y_train = np_utils.to_categorical(y_train, nb_classes)\n",
      "  56: y_test = np_utils.to_categorical(y_test, nb_classes)\n",
      "  57: \n",
      "  58: \n",
      "  59: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \"\"\"\n",
      "   4:     Model providing function:\n",
      "   5: \n",
      "   6:     Create Keras model with double curly brackets dropped-in as needed.\n",
      "   7:     Return value has to be a valid python dictionary with two customary keys:\n",
      "   8:         - loss: Specify a numeric evaluation metric to be minimized\n",
      "   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
      "  10:     The last one is optional, though recommended, namely:\n",
      "  11:         - model: specify the model just created so that we can later use it again.\n",
      "  12:     \"\"\"\n",
      "  13:     model = Sequential()\n",
      "  14:     model.add(Dense(512, input_shape=(80,80,1)))\n",
      "  15:     model.add(Activation('relu'))\n",
      "  16:     model.add(Dropout(space['Dropout']))\n",
      "  17:     model.add(Dense(space['Dense']))\n",
      "  18:     model.add(Activation(space['Activation']))\n",
      "  19:     model.add(Dropout(space['Dropout_1']))\n",
      "  20: \n",
      "  21:     # If we choose 'four', add an additional fourth layer\n",
      "  22:     if space['Dropout_2'] == 'four':\n",
      "  23:         model.add(Dense(100))\n",
      "  24: \n",
      "  25:         # We can also choose between complete sets of layers\n",
      "  26: \n",
      "  27:         model.add(space['add'])\n",
      "  28:         model.add(Activation('relu'))\n",
      "  29: \n",
      "  30:     model.add(Flatten())\n",
      "  31:     model.add(Dense(2, activation='softmax'))\n",
      "  32:     \n",
      "  33:     model.summary()\n",
      "  34: \n",
      "  35:     model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
      "  36:                   optimizer=space['optimizer'])\n",
      "  37: \n",
      "  38:     result = model.fit(x_train, y_train,\n",
      "  39:               batch_size=space['batch_size'],\n",
      "  40:               epochs=2,\n",
      "  41:               verbose=2,\n",
      "  42:               validation_split=0.1)\n",
      "  43:     #get the highest validation accuracy of the training epochs\n",
      "  44:     validation_acc = np.amax(result.history['val_acc']) \n",
      "  45:     print('Best validation acc of epoch:', validation_acc)\n",
      "  46:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
      "  47: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 80, 80, 512)       1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 80, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 80, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 80, 80, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 80, 80, 1024)      0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 80, 80, 1024)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6553600)           0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 13107202  \n",
      "=================================================================\n",
      "Total params: 13,633,538                           \n",
      "Trainable params: 13,633,538                       \n",
      "Non-trainable params: 0                            \n",
      "_________________________________________________________________\n",
      "Train on 220 samples, validate on 25 samples       \n",
      "Epoch 1/2                                          \n",
      " - 42s - loss: 0.6834 - acc: 0.6318 - val_loss: 0.6599 - val_acc: 1.0000\n",
      "\n",
      "Epoch 2/2                                          \n",
      " - 41s - loss: 0.6369 - acc: 0.8000 - val_loss: 0.6402 - val_acc: 0.9600\n",
      "\n",
      "Best validation acc of epoch:                      \n",
      "1.0                                                \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 80, 80, 512)       1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 80, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 80, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 80, 80, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 80, 80, 1024)      0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 80, 80, 1024)      0         \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_2 (Flatten)          (None, 6553600)           0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 13107202  \n",
      "=================================================================\n",
      "Total params: 13,633,538                                      \n",
      "Trainable params: 13,633,538                                  \n",
      "Non-trainable params: 0                                       \n",
      "_________________________________________________________________\n",
      "Train on 220 samples, validate on 25 samples                  \n",
      "Epoch 1/2                                                     \n",
      " - 37s - loss: 5.7016 - acc: 0.5045 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 2/2                                                     \n",
      " - 34s - loss: 7.6508 - acc: 0.5227 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "\n",
      "Best validation acc of epoch:                                 \n",
      "1.0                                                           \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 80, 80, 512)       1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 80, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 80, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 80, 80, 256)       131328    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 80, 80, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 80, 80, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1638400)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 3276802   \n",
      "=================================================================\n",
      "Total params: 3,409,154                                       \n",
      "Trainable params: 3,409,154                                   \n",
      "Non-trainable params: 0                                       \n",
      "_________________________________________________________________\n",
      "Train on 220 samples, validate on 25 samples                  \n",
      "Epoch 1/2                                                     \n",
      " - 13s - loss: 6.8680 - acc: 0.4500 - val_loss: 16.0302 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 2/2                                                     \n",
      " - 12s - loss: 8.3794 - acc: 0.4773 - val_loss: 16.0302 - val_acc: 0.0000e+00\n",
      "\n",
      "Best validation acc of epoch:                                 \n",
      "0.0                                                           \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 80, 80, 512)       1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 80, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 80, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 80, 80, 256)       131328    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 80, 80, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 80, 80, 256)       0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 80, 80, 100)       25700     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 80, 80, 100)       0         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 80, 80, 100)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 640000)            0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 1280002   \n",
      "=================================================================\n",
      "Total params: 1,438,054                                       \n",
      "Trainable params: 1,438,054                                   \n",
      "Non-trainable params: 0                                       \n",
      "_________________________________________________________________\n",
      "Train on 220 samples, validate on 25 samples                  \n",
      "Epoch 1/2                                                     \n",
      " - 13s - loss: 3.9805 - acc: 0.5000 - val_loss: 16.0302 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 2/2                                                     \n",
      " - 12s - loss: 8.3794 - acc: 0.4773 - val_loss: 16.0302 - val_acc: 0.0000e+00\n",
      "\n",
      "Best validation acc of epoch:                                 \n",
      "0.0                                                           \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 80, 80, 512)       1024      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 80, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 80, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 80, 80, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 80, 80, 1024)      0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 80, 80, 1024)      0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 80, 80, 100)       102500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 80, 80, 100)       0         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 80, 80, 100)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 640000)            0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 1280002   \n",
      "=================================================================\n",
      "Total params: 1,908,838                                       \n",
      "Trainable params: 1,908,838                                   \n",
      "Non-trainable params: 0                                       \n",
      "_________________________________________________________________\n",
      "Train on 220 samples, validate on 25 samples                  \n",
      "Epoch 1/2                                                     \n",
      " - 34s - loss: 3.9319 - acc: 0.4682 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 2/2                                                     \n",
      " - 31s - loss: 7.6508 - acc: 0.5227 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "\n",
      "Best validation acc of epoch:                                 \n",
      "1.0                                                           \n",
      "100%|██████████| 5/5 [04:33<00:00, 56.55s/it, best loss: -1.0]\n",
      "Evalutation of best performing model:\n",
      "105/105 [==============================] - 3s 27ms/step\n",
      "[0.6192127676237197, 0.8285714291390919]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Dense': 2, 'Activation': 0, 'batch_size': 1, 'Dropout_1': 0.7371698374615214, 'add': 0, 'Dropout_2': 0, 'optimizer': 2, 'Dropout': 0.6108763092812357}\n"
     ]
    }
   ],
   "source": [
    "def data():\n",
    "    \"\"\"\n",
    "    Data providing function:\n",
    "\n",
    "    This function is separated from create_model() so that hyperopt\n",
    "    won't reload data for each evaluation run.\n",
    "    \"\"\"  \n",
    "    cell_data = os.listdir('training_data/cell/')\n",
    "    nocell_data = os.listdir('training_data/nocell/')\n",
    "\n",
    "    # Training data\n",
    "    path = 'training_data/cell/'\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for f in cell_data:\n",
    "        im = mpimg.imread(str(path)+f)\n",
    "        x_train.append(im)\n",
    "        y_train.append(1)\n",
    "    path = 'training_data/nocell/'\n",
    "    for f in nocell_data:\n",
    "        im = mpimg.imread(str(path)+f)\n",
    "        x_train.append(im)\n",
    "        y_train.append(0)\n",
    "\n",
    "    cell_test_data = os.listdir('test_data/cell/')\n",
    "    nocell_test_data = os.listdir('test_data/nocell/')\n",
    "\n",
    "    # Validation data\n",
    "    path = 'test_data/cell/'\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    for f in cell_test_data:\n",
    "        im = mpimg.imread(str(path)+f)\n",
    "        x_test.append(im)\n",
    "        y_test.append(1)\n",
    "    path = 'test_data/nocell/'\n",
    "    for f in nocell_test_data:\n",
    "        im = mpimg.imread(str(path)+f)\n",
    "        x_test.append(im)\n",
    "        y_test.append(0)\n",
    "        \n",
    "    \n",
    "    x_train = np.asarray(x_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.float32)\n",
    "    x_test = np.asarray(x_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.float32)\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], 80, 80, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 80, 80, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    nb_classes = 2\n",
    "    y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(80,80,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([256, 512, 1024])}}))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    # If we choose 'four', add an additional fourth layer\n",
    "    if {{choice(['three', 'four'])}} == 'four':\n",
    "        model.add(Dense(100))\n",
    "\n",
    "        # We can also choose between complete sets of layers\n",
    "\n",
    "        model.add({{choice([Dropout(0.5), Activation('linear')])}})\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "\n",
    "    result = model.fit(x_train, y_train,\n",
    "              batch_size={{choice([64, 128])}},\n",
    "              epochs=2,\n",
    "              verbose=2,\n",
    "              validation_split=0.1)\n",
    "    #get the highest validation accuracy of the training epochs\n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name='hyperas')\n",
    "    X_train, Y_train, X_test, Y_test = data()\n",
    "    print(\"Evalutation of best performing model:\")\n",
    "    print(best_model.evaluate(X_test, Y_test))\n",
    "    print(\"Best performing model chosen hyper-parameters:\")\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cell_data = os.listdir('training_data/cell/')\n",
    "nocell_data = os.listdir('training_data/nocell/')\n",
    "\n",
    "# Training data\n",
    "path = 'training_data/cell/'\n",
    "x_train = []\n",
    "y_train = []\n",
    "for f in cell_data:\n",
    "    im = mpimg.imread(str(path)+f)\n",
    "    x_train.append(im)\n",
    "    y_train.append(1)\n",
    "path = 'training_data/nocell/'\n",
    "for f in nocell_data:\n",
    "    im = mpimg.imread(str(path)+f)\n",
    "    x_train.append(im)\n",
    "    y_train.append(0)\n",
    "    \n",
    "cell_test_data = os.listdir('test_data/cell/')\n",
    "nocell_test_data = os.listdir('test_data/nocell/')\n",
    "    \n",
    "# Validation data\n",
    "path = 'test_data/cell/'\n",
    "x_test = []\n",
    "y_test = []\n",
    "for f in cell_test_data:\n",
    "    im = mpimg.imread(str(path)+f)\n",
    "    x_test.append(im)\n",
    "    y_test.append(1)\n",
    "path = 'test_data/nocell/'\n",
    "for f in nocell_test_data:\n",
    "    im = mpimg.imread(str(path)+f)\n",
    "    x_test.append(im)\n",
    "    y_test.append(0)\n",
    "    \n",
    "print(x_train, y_train, x_test, y_test) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
